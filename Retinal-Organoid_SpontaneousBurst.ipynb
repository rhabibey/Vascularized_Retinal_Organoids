{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retinal Organoid SpontaneousBurst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spontaneous bursts has been extracted by Neuroexplorer into an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read excel file of Nex-export\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory_path = r'C:\\Baseline'\n",
    "excel_files = [f for f in os.listdir(directory_path) if f.endswith('.xlsx')]\n",
    "all_cleaned_data = {}\n",
    "\n",
    "for file in excel_files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    sheet_names = pd.ExcelFile(file_path).sheet_names\n",
    "    cleaned_data = {}\n",
    "    for sheet in sheet_names:\n",
    "        if sheet == \"Sheet1\":\n",
    "            continue\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "        cleaned_df = df[df.iloc[:, 1] != 'nr_001']\n",
    "        cleaned_data[sheet] = cleaned_df\n",
    "    all_cleaned_data[file] = cleaned_data\n",
    "\n",
    "output_directory_path = r'C:\\Baseline_cleaned'\n",
    "os.makedirs(output_directory_path, exist_ok=True)\n",
    "\n",
    "for file, cleaned_data in all_cleaned_data.items():\n",
    "    if file.startswith(\"01\"):\n",
    "        new_file_name = \"02\" + file[2:]\n",
    "    else:\n",
    "        new_file_name = file\n",
    "    output_file_path = os.path.join(output_directory_path, new_file_name)\n",
    "    with pd.ExcelWriter(output_file_path) as writer:\n",
    "        for sheet, cleaned_df in cleaned_data.items():\n",
    "            cleaned_df.to_excel(writer, sheet_name=sheet, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "directory_path = r'C:\\Baseline_cleaned'\n",
    "threshold = 0.1\n",
    "column_name = 'Mean Freq.'\n",
    "excel_files = [f for f in os.listdir(directory_path) if f.endswith('.xlsx')]\n",
    "all_cleaned_data = {}\n",
    "\n",
    "for file in excel_files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    sheet_names = pd.ExcelFile(file_path).sheet_names\n",
    "    cleaned_data = {}\n",
    "    for sheet in sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "        if column_name in df.columns:\n",
    "            cleaned_df = df[df[column_name] >= threshold]\n",
    "        else:\n",
    "            cleaned_df = df\n",
    "        cleaned_data[sheet] = cleaned_df\n",
    "    all_cleaned_data[file] = cleaned_data\n",
    "\n",
    "output_directory_path = r'C:\\Baseline_SFFilter'\n",
    "os.makedirs(output_directory_path, exist_ok=True)\n",
    "for file, cleaned_data in all_cleaned_data.items():\n",
    "    if file.startswith(\"02_Burst\"):\n",
    "        new_file_name = \"03_SF\" + file[2:]\n",
    "    else:\n",
    "        new_file_name = file\n",
    "    output_file_path = os.path.join(output_directory_path, new_file_name)\n",
    "    with pd.ExcelWriter(output_file_path) as writer:\n",
    "        for sheet, cleaned_df in cleaned_data.items():\n",
    "            cleaned_df.to_excel(writer, sheet_name=sheet, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "excel_file_path = r'C:\\Baseline_SFFilter.xlsx'\n",
    "xls = pd.ExcelFile(excel_file_path)\n",
    "variables = ['Mean Freq.']\n",
    "data = {var: {} for var in variables}\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "    for var in variables:\n",
    "        if var in df.columns:\n",
    "            data[var][sheet_name] = df[var].values\n",
    "\n",
    "final_data_frames = {}\n",
    "for var in variables:\n",
    "    arrays = [data[var][sheet] for sheet in data[var]]\n",
    "    max_length = max(len(arr) for arr in arrays)\n",
    "    padded_arrays = [np.pad(arr.astype(float), (0, max_length - len(arr)), mode='constant', constant_values=np.nan) for arr in arrays]\n",
    "    final_data_frames[var] = pd.DataFrame(padded_arrays, columns=range(max_length), index=data[var].keys()).transpose()\n",
    "\n",
    "output_file_path = r'C:\\Baseline_Avg.xlsx'\n",
    "with pd.ExcelWriter(output_file_path) as writer:\n",
    "    for var, df in final_data_frames.items():\n",
    "        df.to_excel(writer, sheet_name=var, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "excel_file_path = r'C:\\Baseline_Avg.xlsx'\n",
    "xls = pd.ExcelFile(excel_file_path)\n",
    "output_file_path = r'C:\\Baseline_Avg2.xlsx'\n",
    "with pd.ExcelWriter(output_file_path) as writer:\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(excel_file_path, sheet_name=sheet_name, header=0)\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "        stats_data = pd.DataFrame()\n",
    "        for sample_name in df.columns:\n",
    "            data = df[sample_name]\n",
    "            mean = data.mean()\n",
    "            count = data.count()\n",
    "            median = data.median()\n",
    "            max_val = data.max()\n",
    "            min_val = data.min()\n",
    "            std = data.std()\n",
    "            sem = data.sem()\n",
    "\n",
    "            stat_df = pd.DataFrame({\n",
    "                'Sample Name': [sample_name],\n",
    "                'Average': [mean],\n",
    "                'Count': [count],\n",
    "                'Median': [median],\n",
    "                'Max': [max_val],\n",
    "                'Min': [min_val],\n",
    "                'SD': [std],\n",
    "                'SEM': [sem]\n",
    "            })\n",
    "            stats_data = pd.concat([stats_data, stat_df], ignore_index=True)\n",
    "        stats_data.to_excel(writer, sheet_name=f'{sheet_name}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupping\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\Baseline_Avg2.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "processed_sheets = {}\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = pd.read_excel(xls, sheet_name)\n",
    "    df['Week'] = df['Sample Name'].str[:3]\n",
    "    df['Group'] = df['Sample Name'].apply(lambda x: 'Vascularized' if 'VASCU' in x else 'Non_Vascularized')\n",
    "    new_columns = ['Group', 'Week'] + [col for col in df.columns if col not in ['Group', 'Week']]\n",
    "    df = df[new_columns]\n",
    "    processed_sheets[sheet_name] = df\n",
    "output_file_path = r\"C:\\Baseline_Groupped.xlsx\"\n",
    "with pd.ExcelWriter(output_file_path) as writer:\n",
    "    for sheet_name, df in processed_sheets.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove outliers, Plot, save for Prism import\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "colors = {'Non_Vascularized': 'gray', 'Vascularized': 'lightcoral'}\n",
    "\n",
    "file_path = r\"C:\\Baseline_Groupped.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "def remove_outliers(df, column):\n",
    "    def _remove_outliers(group):\n",
    "        Q1 = group[column].quantile(0.25)\n",
    "        Q3 = group[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        return group[~((group[column] < (Q1 - 3 * IQR)) | (group[column] > (Q3 + 5 * IQR)))]\n",
    "    return df.groupby(['Group', 'Week']).apply(_remove_outliers).reset_index(drop=True)\n",
    "\n",
    "def calculate_group_statistics(df):\n",
    "    group_stats = df.groupby(['Week', 'Group'])['Average'].agg(['mean', 'std', 'sem', 'max', 'min', 'count']).reset_index()\n",
    "    group_counts = df.groupby('Group')['Average'].count().reset_index()\n",
    "    group_stats['Count'] = group_counts['Average']\n",
    "    return group_stats\n",
    "\n",
    "processed_data = {}\n",
    "variable_stats_raw = {}\n",
    "variable_stats_cleaned = {}\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = pd.read_excel(xls, sheet_name)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['Week', 'Average'])\n",
    "    group_stats_raw = calculate_group_statistics(df)\n",
    "    variable_stats_raw[sheet_name] = group_stats_raw\n",
    "    # --------------------- Remove outliers --------------------\n",
    "    df_cleaned = remove_outliers(df, 'Average')\n",
    "    processed_data[sheet_name] = df_cleaned\n",
    "    group_stats = calculate_group_statistics(df_cleaned)\n",
    "    variable_stats_cleaned[sheet_name] = group_stats\n",
    "    group_order = ['Non_Vascularized', 'Vascularized']\n",
    "    plt.figure(figsize=(7, 6)) \n",
    "    ax=sns.boxplot(data=df_cleaned, x='Week', y='Average', hue='Group', \n",
    "                order=['w17', 'w20', 'w23'],\n",
    "                hue_order=group_order, palette=colors, showfliers=False, width=0.5)  \n",
    "    sns.stripplot(data=df_cleaned, x='Week', y='Average', hue='Group', \n",
    "                  order=['w17', 'w20', 'w23'],\n",
    "                  hue_order=group_order, dodge=True, jitter=True, edgecolor='black', linewidth=0.5, palette=colors, \n",
    "                  alpha=0.7, size=4, ax=ax)  \n",
    "    means = df_cleaned.groupby(['Week', 'Group'])['Average'].mean().reset_index()\n",
    "    for group, color in colors.items():\n",
    "        plt.plot(means[means['Group'] == group]['Week'], means[means['Group'] == group]['Average'], \n",
    "                 color='black', linestyle='-', linewidth=1, marker='o', markersize=3, markeredgecolor='black',\n",
    "                 markeredgewidth=2)  \n",
    "\n",
    "    for group, color in colors.items():\n",
    "        sems = df_cleaned.groupby(['Week', 'Group'])['Average'].sem().reset_index()\n",
    "        group_sems = sems[sems['Group'] == group]\n",
    "        for dpi in ['w17', 'w20', 'w23']:\n",
    "            dpi_sems = group_sems[group_sems['Week'] == dpi]\n",
    "            plt.errorbar(dpi_sems['Week'], means[(means['Group'] == group) & (means['Week'] == dpi)]['Average'], \n",
    "                         yerr=dpi_sems['Average'], fmt='o', color=color, markersize=10, capsize=5, \n",
    "                         markeredgecolor='black', linewidth=1, ecolor='black') \n",
    "    \n",
    "    plt.xticks(rotation=45, fontsize=16)\n",
    "    \n",
    "    # Set the y-axis to log scale and fixed maximum\n",
    "    #ax.set_yscale('log')\n",
    "    #ax.set_ylim(1e0, 1e2)  # Adjust the limits according to your data\n",
    "    \n",
    "    plt.legend(title='Group', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xlabel('Week', fontsize=16)  \n",
    "    plt.ylabel('Average', fontsize=18)  \n",
    "    plt.title(f'{sheet_name}', fontsize=18)  \n",
    "    plt.yticks(fontsize=16)  \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    output_directory= r'C:\\007_Stats'\n",
    "    pdf_filename = f\"{output_directory}/Ex02Ex04_{sheet_name}.pdf\"\n",
    "    plt.savefig(pdf_filename, format='pdf')\n",
    "    plt.show()\n",
    "\n",
    "output_excel_path = r\"C:\\Baseline_Stat.xlsx\"\n",
    "with pd.ExcelWriter(output_excel_path) as writer:\n",
    "    for variable, stats in variable_stats_raw.items():\n",
    "        stats.to_excel(writer, sheet_name=f\"{variable}_raw\", index=False)\n",
    "    for variable, stats in variable_stats_cleaned.items():\n",
    "        stats.to_excel(writer, sheet_name=f\"{variable}_clean\", index=False)\n",
    "output_excel_path_cleaned = r\"C:\\Baseline_OutliersRemoved.xlsx\"\n",
    "with pd.ExcelWriter(output_excel_path_cleaned) as writer_cleaned:\n",
    "    for sheet_name, data in processed_data.items():\n",
    "        data.to_excel(writer_cleaned, sheet_name=sheet_name, index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
